---
title: Training Models
description: Configure and train AI models on your hardware data
---

This tutorial covers the complete workflow for training models in Onyx Engine, from defining your model structure to monitoring training progress.

## Complete Training Example

Here's a full training script you can use as a starting point:

```python
from onyxengine import Onyx
from onyxengine.modeling import (
    Output,
    Input,
    MLPConfig,
    TrainingConfig,
    AdamWConfig,
)

# Initialize the client (defaults to ONYX_API_KEY env var)
onyx = Onyx()

# Define model outputs and inputs
outputs = [
    Output(name='acceleration'),
]
inputs = [
    Input(name='velocity', parent='acceleration', relation='derivative'),
    Input(name='position', parent='velocity', relation='derivative'),
    Input(name='control_input'),
]

# Configure the model
model_config = MLPConfig(
    outputs=outputs,
    inputs=inputs,
    dt=0.0025,
    sequence_length=8,
    hidden_layers=3,
    hidden_size=64,
    activation='relu',
    dropout=0.2,
    bias=True
)

# Configure training
training_config = TrainingConfig(
    training_iters=3000,
    train_batch_size=1024,
    test_dataset_size=500,
    checkpoint_type='multi_step',
    optimizer=AdamWConfig(lr=3e-4, weight_decay=1e-2),
    lr_scheduler=None
)

# Start training
onyx.train_model(
    model_name='my_first_model',
    model_config=model_config,
    dataset_name='example_data',
    training_config=training_config,
)
```

## Defining Model Inputs and Outputs

To make your life easier for hardware dynamics modeling, Onyx provides some built-in tools for creating inputs/outputs with **physical relationships**, **traceable naming**, and **feature scaling**. 

### Outputs

Outputs are the features your model predicts. You can define multiple outputs and include `parent` and `relation` to derive outputs from other outputs.

```python
from onyxengine.modeling import Output

outputs = [
    Output(name='jerk'),
    Output(name='acceleration', parent='jerk', relation='derivative'),
    Output(name='temperature_delta')
]
```

### Inputs

Inputs are the features fed into the model to make predictions. Similarly, you can define multiple inputs and include `parent` and `relation` to derive inputs from both outputs and other inputs.

```python
from onyxengine.modeling import Input

inputs = [
    # Feed back acceleration to the model as an input
    Input(name='acceleration_feedback', parent='acceleration', relation='equal'),
    # Derive velocity and position from acceleration
    Input(name='velocity', parent='acceleration', relation='derivative'),
    Input(name='position', parent='velocity', relation='derivative'),
    # Sometimes delta values can be more useful/intuitive versus derivatives
    Input(name='temperature', parent='temperature_delta', relation='delta'),
    Input(name='control_input'),
]
```

### Feature Relationships

The `parent` parameter specifies the feature to derive from. The `relation` parameter specifies the mathematical relationship:

| Relation | Equation | Use Case |
|----------|----------|----------|
| `'derivative'` | `state[t+1] = state[t] + parent[t] * dt` | Predicting/using time derivatives |
| `'delta'` | `state[t+1] = state[t] + parent[t]` | Predicting more general deltas |
| `'equal'` | `state[t+1] = parent[t]` | Feed output back as input |


### Feature Naming

By default, the `name` parameter will be used to find the input/output's matching feature in the dataset when training the model. If you want to use a different name for the input/output, you can use the `dataset_feature` parameter.

```python
# Model input name matches the dataset feature name
Input(name='encoder_position_radians')

# Model input 'position' uses the 'encoder_position_radians' dataset feature
Input(name='position', dataset_feature='encoder_position_radians')

# Dataset features can be used multiple times
Input(name='current_position', dataset_feature='encoder_position_radians')
Output(name='next_position_pred', dataset_feature='encoder_position_radians')
```

<Note>
Model input/output names must be unique.
</Note>

### Feature Scaling

When training AI models, it's important to scale inputs/outputs so that they are in similar ranges. 
For example, if you were training a model with outputs `Pressure [Pascal]` and `Torque [Newton-Meters]`, the values for pressure (and therefore loss/gradients) would be much larger than the values for torque, which would encourage the model to focus on learning to predict pressure and potentially ignore torque.

To address this, it's typical to scale all features to have a mean of `0` and standard deviation of `1`, or range from `[-1, 1]` or `[0, 1]`. 
Keeping track of the scaling factors of each feature for use in both training and deployment is prone to error, so Onyx keeps the scaling factors bundled with each model version for you:
- `train_mean`: The mean of the dataset feature during training
- `train_std`: The standard deviation of the dataset feature during training
- `train_min`: The minimum value of the dataset feature during training
- `train_max`: The maximum value of the dataset feature during training
- `scale`: The scaling method used, either `"mean"` or `[min, max]` (see section below)

```json
{
    "name": "example_model",
    "type": "model",
    "created_at": "2026-01-20T19:56:25.969196+00:00",
    "config": {
        "type": "rnn",
        "outputs": [
            {
                "type": "output",
                "name": "acceleration",
                "dataset_feature": "acceleration",
                "scale": "mean",
                "parent": None,
                "relation": None,
                "train_mean": -5.359800977241818,
                "train_std": 4.525139292151637,
                "train_min": -19.051991812957425,
                "train_max": 0.5755097293625168,
            }
        ],
        "inputs": [
            {
                "type": "input",
                "name": "velocity",
                "dataset_feature": "velocity",
                "scale": "mean",
                "parent": None,
                "relation": None,
                "train_mean": 4.896938152458872,
                "train_std": 6.035669440028341,
                "train_min": -0.8852670185723328,
                "train_max": 30.22476247402063,
            },
        ...

```

The `scale` parameter controls how model inputs/outputs are scaled:

- **`"mean"`** (default): Scales the feature to have a mean of `0` and std of `1`.
- **`[min, max]`**: For dataset features with known physical bounds, scales from `[min, max]` to `[-1, 1]`.

Often, just leaving the default `"mean"` scaling is fine for most features (bounded or not).

```python
from onyxengine.modeling import Input, Output

# Mean scaling (default): always use when feature distribution is unknown
Output(name='acceleration')
Input(name='velocity', scale='mean')

# Min-max scaling: can be used when feature has known min/max (e.g. voltage 0–5 V, PWM 0–1)
Input(name='voltage', dataset_feature='voltage_V', scale=[0.0, 5.0]),   # 0–5 V → [-1, 1]
Input(name='pwm_input', dataset_feature='duty', scale=[0.0, 1.0]),     # 0–100% → [-1, 1]
```

## Model Configuration

### MLP (Multi-Layer Perceptron)

Best for systems with relatively simple dynamics:

```python
from onyxengine.modeling import MLPConfig

model_config = MLPConfig(
    outputs=outputs,
    inputs=inputs,
    dt=0.0025,              # Time step (must match dataset)
    sequence_length=8,       # Input history length
    hidden_layers=3,         # Number of hidden layers
    hidden_size=64,          # Neurons per layer
    activation='relu',       # Activation function
    dropout=0.2,             # Regularization
    bias=True                # Include bias terms
)
```

### RNN (Recurrent Neural Network)

Better for systems with complex temporal dependencies:

```python
from onyxengine.modeling import RNNConfig

model_config = RNNConfig(
    outputs=outputs,
    inputs=inputs,
    dt=0.0025,
    sequence_length=10,
    rnn_type='LSTM',         # 'RNN', 'LSTM', or 'GRU'
    hidden_layers=2,
    hidden_size=64,
    dropout=0.1,
    bias=True
)
```

### Transformer

Powerful for capturing long-range dependencies:

```python
from onyxengine.modeling import TransformerConfig

model_config = TransformerConfig(
    outputs=outputs,
    inputs=inputs,
    dt=0.0025,
    sequence_length=10,
    n_layer=2,               # Transformer layers
    n_head=4,                # Attention heads
    n_embd=64,               # Embedding dimension
    dropout=0.2,
    bias=True
)
```

<Note>
For `TransformerConfig`, `n_embd` must be divisible by `n_head`.
</Note>

## Training Configuration

```python
from onyxengine.modeling import TrainingConfig, AdamWConfig

training_config = TrainingConfig(
    training_iters=2000,          # Total training iterations
    train_batch_size=1024,        # Samples per batch
    train_val_split_ratio=0.9,    # Train/validation split
    test_dataset_size=500,        # Samples for test visualization
    checkpoint_type='single_step', # Optimization target
    optimizer=AdamWConfig(lr=3e-4, weight_decay=1e-2),
    lr_scheduler=None             # Optional learning rate scheduler
)
```

### Checkpoint Types

| Type | Description | Use Case |
|------|-------------|----------|
| `'single_step'` | Optimize for next-step prediction | General training, debugging |
| `'multi_step'` | Optimize for trajectory simulation | Final model selection |

<Tip>
Start with `single_step` to verify your model learns the dynamics, then switch to `multi_step` for deployment-ready models.
</Tip>

### Optimizers

**AdamW** (recommended for most cases):

```python
from onyxengine.modeling import AdamWConfig

optimizer = AdamWConfig(
    lr=3e-4,           # Learning rate
    weight_decay=1e-2  # L2 regularization
)
```

**SGD** (for fine-tuning or specific cases):

```python
from onyxengine.modeling import SGDConfig

optimizer = SGDConfig(
    lr=1e-3,
    weight_decay=1e-4,
    momentum=0.9
)
```

### Learning Rate Schedulers

**Cosine Decay with Warmup**:

```python
from onyxengine.modeling import CosineDecayWithWarmupConfig

lr_scheduler = CosineDecayWithWarmupConfig(
    max_lr=3e-4,        # Peak learning rate
    min_lr=3e-5,        # Final learning rate
    warmup_iters=200,   # Warmup period
    decay_iters=1000    # Decay period
)
```

**Cosine Annealing with Warm Restarts**:

```python
from onyxengine.modeling import CosineAnnealingWarmRestartsConfig

lr_scheduler = CosineAnnealingWarmRestartsConfig(
    T_0=500,           # Initial cycle length
    T_mult=2,          # Cycle length multiplier
    eta_min=1e-5       # Minimum learning rate
)
```

## Running Training

```python
onyx.train_model(
    model_name='my_model',           # Name for the trained model
    model_config=model_config,
    dataset_name='my_dataset',       # Dataset to train on
    dataset_version_id=None,         # Optional: specific dataset version
    training_config=training_config,
)
```

Monitor training progress via the [Engine Platform](https://engine.onyx-robotics.com) for detailed loss curves and predictions.

## After Training

### Load Your Model

```python
from onyxengine import Onyx

onyx = Onyx()
model = onyx.load_model('my_model')
print(model.config)
```

### Load a Specific Version

```python
from onyxengine import Onyx

onyx = Onyx()
model = onyx.load_model('my_model', version_id='dcfec841-1748-47e2-b6c7-3c821cc69b4a')
```

## Tips for Better Training

<AccordionGroup>
  <Accordion title="Start with more sequence length">
    If your initial results are poor, try increasing `sequence_length`. This gives the model more temporal context.
  </Accordion>

  <Accordion title="Match dt to your data">
    The `dt` parameter must match your dataset's actual time step. Incorrect values cause integration errors during simulation.
  </Accordion>

  <Accordion title="Use dropout for regularization">
    Values between 0.1 and 0.3 typically work well. Increase if you see overfitting (training loss much lower than validation loss).
  </Accordion>

  <Accordion title="Try different architectures">
    If an MLP isn't capturing your dynamics, try an RNN or Transformer. Each architecture has different strengths for different system types.
  </Accordion>
</AccordionGroup>

## Next Steps

<CardGroup cols={2}>
  <Card title="Optimizing Models" icon="sliders-horizontal" href="/tutorials/optimizing-models">
    Automatically search for the best hyperparameters
  </Card>
  <Card title="Simulating Models" icon="play" href="/tutorials/simulating-models">
    Deploy your trained model for simulation
  </Card>
</CardGroup>
